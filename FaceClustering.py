# -*- coding: utf-8 -*-
"""CS146_Winter2023_PS4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ckCcs_x_s2MDmRokQxfRk5fTNcik6O62

# PCA and k-means

## Setting up
"""

"""
Author      : Yi-Chieh Wu, Sriram Sankararaman
"""
import time

# numpy and scipy libraries
import numpy as np
from scipy import stats

# matplotlib libraries
import matplotlib.pyplot as plt
import collections

# To add your own Drive Run this cell.
from google.colab import drive
drive.mount('/content/gdrive')

import sys
# Change the path below to the path where your folder locates
# where you have util.py
### ========== TODO : START ========== ###
sys.path.append('/content/gdrive/My Drive/CS M146/PS4')
### ========== TODO : START ========== ###

import util
from util import *

"""## Point, Cluster and Set of Clusters classes"""

######################################################################
# classes
######################################################################

class Point(object) :

    def __init__(self, name, label, attrs) :
        """
        A data point.

        Attributes
        --------------------
            name  -- string, name
            label -- string, label
            attrs -- numpy arrray of shape (d, ) where d is the number of features
        """

        self.name = name
        self.label = label
        self.attrs = attrs


    #============================================================
    # utilities
    #============================================================

    def distance(self, other) :
        """
        Return Euclidean distance of this point with other point.

        Parameters
        --------------------
            other -- Point, point to which we are measuring distance

        Returns
        --------------------
            dist  -- float, Euclidean distance
        """
        # Euclidean distance metric
        return np.linalg.norm(self.attrs-other.attrs)


    def __str__(self) :
        """
        Return string representation.
        """
        return "%s : (%s, %s)" % (self.name, str(self.attrs), self.label)

class Cluster(object) :

    def __init__(self, points) :
        """
        A cluster (set of points).

        Attributes
        --------------------
            points -- list of Points, cluster elements
        """
        self.points = points


    def __str__(self) :
        """
        Return string representation.
        """
        s = ""
        for point in self.points :
            s += str(point)
        return s

    #============================================================
    # utilities
    #============================================================

    def purity(self) :
        """
        Compute cluster purity.

        Returns
        --------------------
            n           -- int, number of points in this cluster
            num_correct -- int, number of points in this cluster
                                with label equal to most common label in cluster
        """
        labels = []
        for p in self.points :
            labels.append(p.label)

        cluster_label, count = stats.mode(labels)
        return len(labels), np.float64(count)


    def centroid(self) :
        """
        Compute centroid of this cluster.

        Returns
        --------------------
            centroid -- Point, centroid of cluster
        """

        ### ========== TODO : START ========== ###
        # part 2b: implement
        # set the centroid label to any value (e.g. the most common label in this cluster)
        mean = np.mean([point.attrs for point in self.points], axis = 0)

        labels = [point.label for point in self.points]
        centroid_label = None

        if labels:
          centroid_label = max(labels, key= labels.count)

        centroid = Point('centroid', label = centroid_label, attrs=mean)
        return centroid
        ### ========== TODO : END ========== ###


    def medoid(self) :
        """
        Compute medoid of this cluster, that is, the point in this cluster
        that is closest to all other points in this cluster.

        Returns
        --------------------
            medoid -- Point, medoid of this cluster
        """

        ### ========== TODO : START ========== ###
        # part 2b: implement
        # pairwise distances
        pair_dist = np.zeros((len(self.points), len(self.points)))

        for i in range(len(self.points)):
          for j in range(len(self.points)):
            if i != j:
              pair_dist[i][j] = np.linalg.norm(self.points[i].attrs - self.points[j].attrs)

        #sum of the distances
        sum_dist = np.zeros(len(self.points))
        for i in range(len(self.points)):
          for j in range(len(self.points)):
            if i != j:
              sum_dist[i] += pair_dist[i][j]


        med_ind = np.argmin(sum_dist)
        medoid = self.points[med_ind]
        return medoid
        ### ========== TODO : END ========== ###


    def equivalent(self, other) :
        """
        Determine whether this cluster is equivalent to other cluster.
        Two clusters are equivalent if they contain the same set of points
        (not the same actual Point objects but the same geometric locations).

        Parameters
        --------------------
            other -- Cluster, cluster to which we are comparing this cluster

        Returns
        --------------------
            flag  -- bool, True if both clusters are equivalent or False otherwise
        """

        if len(self.points) != len(other.points) :
            return False

        matched = []
        for point1 in self.points :
            for point2 in other.points :
                if point1.distance(point2) == 0 and point2 not in matched :
                    matched.append(point2)
        return len(matched) == len(self.points)

class ClusterSet(object):

    def __init__(self) :
        """
        A cluster set (set of clusters).

        Parameters
        --------------------
            members -- list of Clusters, clusters that make up this set
        """
        self.members = []


    #============================================================
    # utilities
    #============================================================

    def centroids(self) :
        """
        Return centroids of each cluster in this cluster set.

        Returns
        --------------------
            centroids -- list of Points, centroids of each cluster in this cluster set
        """

        ### ========== TODO : START ========== ###
        # part 2b: implement
        centroids = []
        for cluster in self.members:
          centroids.append(cluster.centroid())

        return centroids
        ### ========== TODO : END ========== ###


    def medoids(self) :
        """
        Return medoids of each cluster in this cluster set.

        Returns
        --------------------
            medoids -- list of Points, medoids of each cluster in this cluster set
        """

        ### ========== TODO : START ========== ###
        # part 2b: implement
        medoids = []
        for cluster in self.members:
          medoids.append(cluster.medoid())
        return medoids
        ### ========== TODO : END ========== ###


    def score(self) :
        """
        Compute average purity across clusters in this cluster set.

        Returns
        --------------------
            score -- float, average purity
        """

        total_correct = 0
        total = 0
        for c in self.members :
            n, n_correct = c.purity()
            total += n
            total_correct += n_correct
        return total_correct / float(total)


    def equivalent(self, other) :
        """
        Determine whether this cluster set is equivalent to other cluster set.
        Two cluster sets are equivalent if they contain the same set of clusters
        (as computed by Cluster.equivalent(...)).

        Parameters
        --------------------
            other -- ClusterSet, cluster set to which we are comparing this cluster set

        Returns
        --------------------
            flag  -- bool, True if both cluster sets are equivalent or False otherwise
        """

        if len(self.members) != len(other.members):
            return False

        matched = []
        for cluster1 in self.members :
            for cluster2 in other.members :
                if cluster1.equivalent(cluster2) and cluster2 not in matched:
                    matched.append(cluster2)
        return len(matched) == len(self.members)


    #============================================================
    # manipulation
    #============================================================

    def add(self, cluster):
        """
        Add cluster to this cluster set (only if it does not already exist).

        If the cluster is already in this cluster set, raise a ValueError.

        Parameters
        --------------------
            cluster -- Cluster, cluster to add
        """

        if cluster in self.members :
            raise ValueError

        self.members.append(cluster)

"""## k-means and k-medoids algorithms"""

from numpy.lib.arraysetops import unique
######################################################################
# k-means and k-medoids
######################################################################

def random_init(points, k) :
    """
    Randomly select k unique elements from points to be initial cluster centers.

    Parameters
    --------------------
        points         -- list of Points, dataset
        k              -- int, number of clusters

    Returns
    --------------------
        initial_points -- list of k Points, initial cluster centers
    """
    ### ========== TODO : START ========== ###
    # part 2c: implement (hint: use np.random.choice)
    indxs = np.random.choice(len(points), size= k, replace= False)
    inits = [points[i] for i in indxs]
    return inits
    ### ========== TODO : END ========== ###


def cheat_init(points) :
    """
    Initialize clusters by cheating!

    Details
    - Let k be number of unique labels in dataset.
    - Group points into k clusters based on label (i.e. class) information.
    - Return medoid of each cluster as initial centers.

    Parameters
    --------------------
        points         -- list of Points, dataset

    Returns
    --------------------
        initial_points -- list of k Points, initial cluster centers
    """
    ### ========== TODO : START ========== ###
    # part 2f: implement

    unique_labels = set(p.label for p in points)
    k = len(unique_labels)
    #print(f'unique labels are{unique_labels}')

    #create k groups
    groups = {label: [] for label in unique_labels}

    #assign the points to their groups
    for point in points:
      label = point.label
      groups[label].append(point)

    initial_points = []
    #compute medoid
    for label in unique_labels:
      cluster = groups[label]
      initial_points.append(Cluster(cluster).medoid())


    return initial_points
    ### ========== TODO : END ========== ###

def kAverages(points, k, average, init='random', plot=False) :
    """
    Cluster points into k clusters using variations of k-means algorithm.

    Parameters
    --------------------
        points  -- list of Points, dataset
        k       -- int, number of clusters
        average -- method of ClusterSet
                   determines how to calculate average of points in cluster
                   allowable: ClusterSet.centroids, ClusterSet.medoids
        init    -- string, method of initialization
                   allowable:
                       'cheat'  -- use cheat_init to initialize clusters
                       'random' -- use random_init to initialize clusters
        plot    -- bool, True to plot clusters with corresponding averages
                         for each iteration of algorithm

    Returns
    --------------------
        k_clusters -- ClusterSet, k clusters
    """
    ### ========== TODO : START ========== ###
    # part 2c,2d: implement

    if average == ClusterSet.centroids:
      cluster_avg = lambda c: c.centroid()
      plot_type = 'kMeans'

    if average == ClusterSet.medoids:
      cluster_avg = lambda c: c.medoid()
      plot_type = 'kMedoid'

    if init == 'random':
      centroids = random_init(points, k)
    if init == 'cheat':
      centroids = cheat_init(points)

    assign = []
    while True:

    #distances between each point and centroid
      dists = [[c.distance(p) for c in centroids] for p in points]

      #assign point to the closest centroid
      new_assign = [np.argmin(d) for d in dists]

      if new_assign == assign:
        break

      assign = new_assign

      clusters = []
      for j in range(k):
        cur_cluster = []
        for i, point in enumerate(points):
          if assign[i] == j:
            cur_cluster.append(point)


        cluster = Cluster(cur_cluster)
        clusters.append(cluster)

      #compute the new centroids
      centroids = [cluster_avg(cluster) for cluster in clusters]
      k_clusters = ClusterSet()
      k_clusters.members = clusters

      if plot:
        plot_clusters(k_clusters, plot_type, average)
      #print(f'centroids are {centroids}')

    return k_clusters
    ### ========== TODO : END ========== ###


def kMeans(points, k, init='random', plot=False) :
    """
    Cluster points into k clusters using variations of k-means algorithm.

    Parameters
    --------------------
        points  -- list of Points, dataset
        k       -- int, number of clusters
        init    -- string, method of initialization
                   allowable:
                       'cheat'  -- use cheat_init to initialize clusters
                       'random' -- use random_init to initialize clusters
        plot    -- bool, True to plot clusters with corresponding averages
                         for each iteration of algorithm

    Returns
    --------------------
        k_clusters -- ClusterSet, k clusters
    """

    ### ========== TODO : START ========== ###
    # part 2c: implement
    # Hints:
    #   (1) On each iteration, keep track of the new cluster assignments
    #       in a separate data structure. Then use these assignments to create
    #       a new ClusterSet object and update the centroids.
    #   (2) Repeat until the clustering no longer changes.
    #   (3) To plot, use plot_clusters(...).

    if init == 'random':
      centroids = random_init(points, k)
    if init == 'cheat':
      centroids = cheat_init(points)


    assign = []
    while True:

    #distances between each point and centroid
      dists = [[c.distance(p) for c in centroids] for p in points]

      #assign point to the closest centroid
      new_assign = [np.argmin(d) for d in dists]

      if new_assign == assign:
        break

      assign = new_assign

      clusters = []
      for j in range(k):
        cur_cluster = []
        for i, point in enumerate(points):
          if assign[i] == j:
            cur_cluster.append(point)

        cluster = Cluster(cur_cluster)
        clusters.append(cluster)

      #compute the new centroids
      centroids = [cluster.centroid() for cluster in clusters]
      k_clusters = ClusterSet()
      k_clusters.members = clusters

      if plot:
        plot_clusters(k_clusters, 'kMeans', ClusterSet.centroids)

    return k_clusters
    ### ========== TODO : END ========== ###


def kMedoids(points, k, init='random', plot=False) :
    """
    Cluster points in k clusters using k-medoids clustering.
    See kMeans(...).
    """
    ### ========== TODO : START ========== ###
    # part 2e: implement
    k_clusters = ClusterSet()
    return k_clusters
    ### ========== TODO : END ========== ###

"""## Utilities"""

######################################################################
# helper functions
######################################################################

def build_face_image_points(X, y) :
    """
    Translate images to (labeled) points.

    Parameters
    --------------------
        X     -- numpy array of shape (n,d), features (each row is one image)
        y     -- numpy array of shape (n,), targets

    Returns
    --------------------
        point -- list of Points, dataset (one point for each image)
    """

    n,d = X.shape

    images = collections.defaultdict(list) # key = class, val = list of images with this class
    for i in range(n) :
        images[y[i]].append(X[i,:])

    points = []
    for face in images :
        count = 0
        for im in images[face] :
            points.append(Point(str(face) + '_' + str(count), face, im))
            count += 1

    return points


def plot_clusters(clusters, title, average) :
    """
    Plot clusters along with average points of each cluster.

    Parameters
    --------------------
        clusters -- ClusterSet, clusters to plot
        title    -- string, plot title
        average  -- method of ClusterSet
                    determines how to calculate average of points in cluster
                    allowable: ClusterSet.centroids, ClusterSet.medoids
    """

    plt.figure()
    np.random.seed(20)
    label = 0
    colors = {}
    centroids = average(clusters)
    for c in centroids :
        coord = c.attrs
        plt.plot(coord[0],coord[1], 'ok', markersize=12)
    for cluster in clusters.members :
        label += 1
        colors[label] = np.random.rand(3,)
        for point in cluster.points :
            coord = point.attrs
            plt.plot(coord[0], coord[1], 'o', color=colors[label])
    plt.title(title)
    plt.show()


def generate_points_2d(N, seed=1234) :
    """
    Generate toy dataset of 3 clusters each with N points.

    Parameters
    --------------------
        N      -- int, number of points to generate per cluster
        seed   -- random seed

    Returns
    --------------------
        points -- list of Points, dataset
    """
    np.random.seed(seed)

    mu = [[0,0.5], [1,1], [2,0.5]]
    sigma = [[0.1,0.1], [0.25,0.25], [0.15,0.15]]

    label = 0
    points = []
    for m,s in zip(mu, sigma) :
        label += 1
        for i in range(N) :
            x = random_sample_2d(m, s)
            points.append(Point(str(label)+'_'+str(i), label, x))

    return points

"""## Main function"""

######################################################################
# main
######################################################################

def main() :
    ### ========== TODO : START ========== ###
    part 1: explore LFW data set

    part 1a
    images, label = get_lfw_data()
    for i in range(5):
      show_image(images[i])

    mean_image = np.mean(images, axis=0)
    show_image(mean_image)

    #part 1b
    U, mu = util.PCA(images)
    plot_gallery([vec_to_image(U[:,i]) for i in range(12)])

    #part 1c
    print('part 1c')
    l_vals = [1, 10, 50, 100, 500, 1288]
    for l in l_vals:
      Z, UI = apply_PCA_from_Eig(images, U, l, mu)
      images_rec = reconstruct_from_PCA(Z, UI, mu)
      print(f'recostructed images with {l} principle components')
      plot_gallery([vec_to_image(images_rec[i,:]) for i in range(12)])

    ### ========== TODO : END ========== ###



    ### ========== TODO : START ========== ###
    part 2d-2f: cluster toy dataset
    np.random.seed(1234)
    points = generate_points_2d(20)

    print(f'using kMeans')
    k_means = kAverages(points, 3, ClusterSet.centroids, init='random', plot=True)
    print(f'using kMedoids')
    k_medoids = kAverages(points, 3, ClusterSet.medoids, init='random', plot=True)

    #cheat_init
    print(f'using kMeans')
    k_means = kAverages(points, 3, ClusterSet.centroids, init='cheat', plot=True)
    print(f'using kMedoids')
    k_medoids = kAverages(points, 3, ClusterSet.medoids, init='cheat', plot=True)



    ### ========== TODO : END ========== ###



    ### ========== TODO : START ========== ###
    # part 3a: cluster faces
    np.random.seed(1234)

    X, y = get_lfw_data()
    X1, y1 = util.limit_pics(X, y, [4, 6, 13, 16], 40)
    points = build_face_image_points(X1, y1)

    kmean_time = []
    kmed_time = []
    kmean_purity = []
    kmed_purity = []


    #kmean
    for i in range(10):
      start_time = time.time()
      kmean_clusters = kAverages(points, 4, ClusterSet.centroids, init='random')
      end_time = time.time()
      kmean_time.append(end_time - start_time)
      kmean_purity.append(kmean_clusters.score())

    #kmedoids
    for i in range(10):
      start_time = time.time()
      kmed_clusters = kAverages(points, 4, ClusterSet.medoids, init='random')
      end_time = time.time()
      kmed_time.append(end_time - start_time)
      kmed_purity.append(kmed_clusters.score())

    print(f"\nAverage k-means purity: {np.mean(kmean_purity):.3f}, min purity: {np.min(kmean_purity):.3f}, max purity: {np.max(kmean_purity):.3f}\
    \nAverage k-means runtime: {np.mean(kmean_time):.3f}, min runtime: {np.min(kmean_time):.3}, max runtime: {np.max(kmean_time):.3}")

    print(f"\nAverage k-medoids purity: {np.mean(kmed_purity):.3f}, min purity: {np.min(kmed_purity):.3f}, max purity: {np.max(kmed_purity):.3f}\
    \nAverage k-medoids runtime: {np.mean(kmed_time):.3f}, min runtime: {np.min(kmed_time):.3}, max runtime: {np.max(kmed_time):.3}")




    # part 3b: explore effect of lower-dimensional representations on clustering performance
    np.random.seed(1234)
    X2, y2 = util.limit_pics(X, y, [4, 13], 40)

    #compute the PCA of entire data
    U, mu = util.PCA(X)

    scores_kmean = []
    scores_kmed = []

    for l in range(1, 50, 2):
      Z, UI = apply_PCA_from_Eig(X2, U, l, mu)
      points = build_face_image_points(Z, y2)

      #compute k-means, k-medoids score on data
      kmean_clusters = kAverages(points, 2, average=ClusterSet.centroids, init='cheat', plot=False)
      kmed_clusters = kAverages(points, 2, average=ClusterSet.medoids, init='cheat', plot=False)

      scores_kmean.append(kmean_clusters.score())
      scores_kmed.append(kmed_clusters.score())

    # Plot the results
    plt.plot(range(1, 50, 2), scores_kmean, label="k-means")
    plt.plot(range(1, 50, 2), scores_kmed, label="k-medoids")
    plt.xlabel("Number of Principal Components")
    plt.ylabel("Clustering Score")
    plt.legend()
    plt.show()


    # part 3c: determine ``most discriminative'' and ``least discriminative'' pairs of images
    np.random.seed(1234)
    num_people = len(np.unique(y))
    pair_scores = []

    for i in range(num_people):
      for j in range(i + 1, num_people):
          #select 40 pics of each i j
          X_pair, y_pair = util.limit_pics(X, y, [i, j], 40)

          #project the data on perinciple component
          Z, UI = apply_PCA_from_Eig(X_pair, U, 50, mu)
          points = build_face_image_points(Z, y_pair)

          kmean_clusters = kAverages(points, 2, average=ClusterSet.centroids, init='cheat', plot=False)
          score = kmean_clusters.score()

          #make a tuple of score and pair of people
          pair_scores.append(((i,j), score))


    most_different = max(pair_scores, key=lambda x: x[1])[0]
    most_similar = min(pair_scores, key=lambda x: x[1])[0]

    print("Most Different Pair:", most_different)
    plot_representative_images(X, y, most_different, title='Most Different Pairs')

    print("Most Similar Pair:", most_similar)
    plot_representative_images(X, y, most_similar, title='Most Similar Pairs')


    ### ========== TODO : END ========== ###


if __name__ == "__main__" :
    main()